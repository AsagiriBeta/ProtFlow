{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwJG790p4yNU"
   },
   "source": [
    "# Modular pipeline for protein structure prediction, pocket detection, and ligand docking\n",
    "\n",
    "**Purpose:**\n",
    "- Parse `.gbk` files to extract protein CDS sequences\n",
    "- Use `esm3-sm-open-v1` (ESM3 small) to predict protein structure (PDB)\n",
    "- Run **P2Rank** for pocket detection\n",
    "- Prepare ligand (SMILES or upload) and run **AutoDock Vina** docking\n",
    "- Generate a simple PDF summary report and provide downloadable PDB/PDBQT files\n",
    "\n",
    "**Before you start (read me):**\n",
    "- Runtime: Designed for Google Colab with GPU enabled (Runtime ‚Üí Change runtime type ‚Üí GPU). Works locally too with minor adjustments.\n",
    "- Hugging Face: You need a token for `esm3-sm-open-v1`. Create one at https://huggingface.co/settings/tokens and grant access to the gated repo if needed.\n",
    "- System deps: Colab step installs Java/OpenBabel/Vina and tools; can be toggled off if you prefer Conda.\n",
    "- ESM3 size: We use the small model to keep memory low on Colab.\n",
    "- Python version: 3.12+ recommended\n",
    "\n",
    "**For antiSMASH analysis:**\n",
    "- Use the separate `AntiSMASH_Colab.ipynb` notebook for BGC annotation\n",
    "\n",
    "Quick switches (ÂèØÈÄâÈ°πÂºÄÂÖ≥):\n",
    "- Set booleans in the \"Cell 0a - Config\" cell to enable/disable steps without editing code elsewhere:\n",
    "  - `INSTALL_SYSTEM_DEPS`: Install system packages (apt) on Colab. Default: True on Colab.\n",
    "  - `INSTALL_MINICONDA`: Install Miniconda via wget (Linux) and prepare Conda. Default: False.\n",
    "  - `ACCEPT_CONDA_TOS`: Automatically accept Conda ToS for required channels if installing Miniconda. Default: True.\n",
    "\n",
    "Conda installation (Linux/Colab) ‚Äî exact commands requested:\n",
    "- If you want to use Conda on Linux/Colab, you can install Miniconda and accept the Conda ToS for Anaconda channels.\n",
    "- These steps are available as a runnable cell below (Cell 1a). The core commands are:\n",
    "\n",
    "```zsh\n",
    "# Download Miniconda (Linux x86_64)\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "# Non-interactive install to a prefix (example)\n",
    "bash Miniconda3-latest-Linux-x86_64.sh -b -p \"$HOME/miniconda\"\n",
    "# Accept Conda ToS for Anaconda main and R channels\n",
    "\"$HOME/miniconda/bin/conda\" tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
    "\"$HOME/miniconda/bin/conda\" tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
    "```\n",
    "\n",
    "ÊèêÁ§∫Ôºà‰∏≠ÊñáÔºâÔºöÂ¶ÇÈúÄÂú®Linux/Colab‰ΩøÁî®CondaÔºåËØ∑ÂÖàÁî®‰∏äÈù¢ÁöÑwgetÂëΩ‰ª§ÂÆâË£ÖMinicondaÔºåÁÑ∂ÂêéÈÄöËøá`conda tos accept`Êé•Âèó‰∏äËø∞‰∏§‰∏™AnacondaÊ∏†ÈÅìÔºàmain‰∏érÔºâÁöÑÊù°Ê¨æ„ÄÇ‰Ω†‰πüÂèØ‰ª•Âú®Êú¨Notebook‰∏≠ÊâìÂºÄ`INSTALL_MINICONDA`ÂºÄÂÖ≥ÔºåÁî±Cell 1aËá™Âä®ÂÆåÊàêÂÆâË£Ö‰∏éÊù°Ê¨æÊé•Âèó„ÄÇ\n",
    "\n",
    "> Colab note: we do not use `requirements.txt` here to avoid potential RDKit/NumPy resolver conflicts on Colab. We install the minimal Python packages directly below (or you can toggle on Conda install).\n"
   ],
   "id": "NwJG790p4yNU"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 0 - Get code (Colab)\n",
    "# If running on Colab (/content exists), clone the repo into /content/ProtFlow if not present,\n",
    "# change directory, and remove any shadowing data folder.\n",
    "from pathlib import Path as __Path\n",
    "if __Path('/content').exists():\n",
    "    # Check if already cloned\n",
    "    if not __Path('/content/ProtFlow').exists():\n",
    "        print('üì• Cloning ProtFlow repository...')\n",
    "        !git clone https://github.com/AsagiriBeta/ProtFlow.git /content/ProtFlow\n",
    "        print('‚úÖ Repository cloned successfully')\n",
    "    else:\n",
    "        print('‚úÖ Repository already exists at /content/ProtFlow')\n",
    "\n",
    "    # Change to repo directory\n",
    "    %cd /content/ProtFlow\n",
    "\n",
    "    # Remove any shadowing folders that might cause import issues\n",
    "    if __Path('/content/esm3_pipeline').exists():\n",
    "        print('üßπ Removing shadowing /content/esm3_pipeline folder...')\n",
    "        !rm -rf /content/esm3_pipeline\n",
    "\n",
    "    print('Working directory:', __Path.cwd())\n",
    "    print('Ready to proceed!')\n",
    "else:\n",
    "    print('Not running on Colab; using current directory.')\n"
   ],
   "id": "6aae8034c8e014b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 0a - Config: optional toggles\n",
    "from pathlib import Path as ___Path\n",
    "ON_COLAB = ___Path('/content').exists()\n",
    "# Toggle whether to install system packages (apt) on Colab\n",
    "INSTALL_SYSTEM_DEPS = True if ON_COLAB else False\n",
    "# Toggle whether to install Miniconda and accept Conda ToS (Linux only)\n",
    "INSTALL_MINICONDA = False\n",
    "# Toggle whether to auto-accept Conda TOS (only used if INSTALL_MINICONDA=True)\n",
    "ACCEPT_CONDA_TOS = True\n",
    "# Where to install Miniconda if enabled\n",
    "CONDA_PREFIX_DIR = '/content/miniconda' if ON_COLAB else str(___Path.home() / 'miniconda')\n",
    "print('ON_COLAB =', ON_COLAB)\n",
    "print('INSTALL_SYSTEM_DEPS =', INSTALL_SYSTEM_DEPS)\n",
    "print('INSTALL_MINICONDA =', INSTALL_MINICONDA)\n",
    "print('ACCEPT_CONDA_TOS =', ACCEPT_CONDA_TOS)\n",
    "print('CONDA_PREFIX_DIR =', CONDA_PREFIX_DIR)\n"
   ],
   "id": "e6b3fbf73e09cff5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 1 - Install dependencies (run once)\n",
    "# Install Python packages with error handling\n",
    "import sys\n",
    "try:\n",
    "    # Check if running on Colab - if so, ensure we have compatible versions\n",
    "    from pathlib import Path as __P0\n",
    "    ON_COLAB_CHECK = __P0('/content').exists()\n",
    "\n",
    "    # Install core packages\n",
    "    print('üì¶ Installing Python packages...')\n",
    "    !pip install -q --upgrade pip\n",
    "\n",
    "    # Install packages in a specific order to avoid conflicts on Colab\n",
    "    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    !pip install -q esm==3.2.1.post1\n",
    "    !pip install -q rdkit biopython py3Dmol tqdm requests reportlab pandas matplotlib huggingface_hub\n",
    "\n",
    "    print('‚úÖ Python packages installed successfully.')\n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Warning during package installation: {e}')\n",
    "    print('Continuing anyway...')\n",
    "\n",
    "# Install system dependencies on Colab\n",
    "from pathlib import Path as __P0\n",
    "if INSTALL_SYSTEM_DEPS and __P0('/content').exists():\n",
    "    print('üì¶ Installing system packages (Colab)...')\n",
    "    !apt-get -qq update > /dev/null 2>&1\n",
    "    !apt-get -qq install -y default-jre openbabel unzip wget python3-tk > /dev/null 2>&1\n",
    "    !apt-get -qq install -y autodock-vina fpocket 2>/dev/null || echo \"Note: autodock-vina/fpocket may not be in default repos\"\n",
    "    print('‚úÖ System packages installed (Colab).')\n",
    "else:\n",
    "    print('‚ÑπÔ∏è Skipping system package install (set INSTALL_SYSTEM_DEPS=True on Colab to enable).')\n",
    "\n",
    "print('‚úÖ Dependencies install finished. If you see any errors, restart runtime and re-run.')\n"
   ],
   "id": "9b53eebf13743f77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 1b - Validate environment (optional but recommended)\n",
    "print('=' * 60)\n",
    "print('üîç Environment Validation')\n",
    "print('=' * 60)\n",
    "\n",
    "validation_results = {}\n",
    "\n",
    "# Check Python version\n",
    "import sys\n",
    "py_version = f\"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\"\n",
    "print(f'Python: {py_version}', end=' ')\n",
    "if sys.version_info >= (3, 9):\n",
    "    print('‚úÖ')\n",
    "    validation_results['python'] = True\n",
    "else:\n",
    "    print('‚ùå (Need 3.9+)')\n",
    "    validation_results['python'] = False\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "try:\n",
    "    import torch\n",
    "    print(f'PyTorch: {torch.__version__}', end=' ')\n",
    "    if torch.cuda.is_available():\n",
    "        print(f'‚úÖ (CUDA {torch.version.cuda})')\n",
    "        validation_results['pytorch'] = True\n",
    "    else:\n",
    "        print('‚ö†Ô∏è (CPU only, no GPU)')\n",
    "        validation_results['pytorch'] = 'cpu'\n",
    "except ImportError:\n",
    "    print('PyTorch: ‚ùå Not installed')\n",
    "    validation_results['pytorch'] = False\n",
    "\n",
    "# Check ESM\n",
    "try:\n",
    "    import esm\n",
    "    print(f'ESM: {esm.__version__} ‚úÖ')\n",
    "    validation_results['esm'] = True\n",
    "except ImportError:\n",
    "    print('ESM: ‚ùå Not installed')\n",
    "    validation_results['esm'] = False\n",
    "\n",
    "# Check BioPython\n",
    "try:\n",
    "    import Bio\n",
    "    print(f'BioPython: {Bio.__version__} ‚úÖ')\n",
    "    validation_results['biopython'] = True\n",
    "except ImportError:\n",
    "    print('BioPython: ‚ùå Not installed')\n",
    "    validation_results['biopython'] = False\n",
    "\n",
    "# Check system tools\n",
    "import shutil\n",
    "tools = {\n",
    "    'Java': 'java',\n",
    "    'OpenBabel': 'obabel',\n",
    "    'AutoDock Vina': 'vina',\n",
    "    'wget': 'wget',\n",
    "    'unzip': 'unzip'\n",
    "}\n",
    "\n",
    "print()\n",
    "print('System tools:')\n",
    "for name, cmd in tools.items():\n",
    "    if shutil.which(cmd):\n",
    "        print(f'  {name}: ‚úÖ')\n",
    "        validation_results[name.lower()] = True\n",
    "    else:\n",
    "        print(f'  {name}: ‚ùå')\n",
    "        validation_results[name.lower()] = False\n",
    "\n",
    "print()\n",
    "all_critical = validation_results.get('python', False) and \\\n",
    "               validation_results.get('pytorch', False) and \\\n",
    "               validation_results.get('esm', False) and \\\n",
    "               validation_results.get('biopython', False)\n",
    "\n",
    "if all_critical:\n",
    "    print('‚úÖ Environment is ready!')\n",
    "else:\n",
    "    print('‚ö†Ô∏è Some critical packages are missing. Please re-run Cell 1.')\n",
    "\n",
    "print()\n",
    "print('Note: Missing system tools will be needed for their respective steps.')\n",
    "print('=' * 60)\n"
   ],
   "id": "fcdc4b367a9a46d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 1a - Optional: Install Miniconda and accept Conda ToS\n",
    "import sys as __sys, os as __os, shutil as __shutil, subprocess as __sp, pathlib as __pl\n",
    "if INSTALL_MINICONDA:\n",
    "    ON_LINUX = __sys.platform.startswith('linux')\n",
    "    prefix = CONDA_PREFIX_DIR\n",
    "    __os.makedirs(prefix, exist_ok=True)\n",
    "    if ON_LINUX:\n",
    "        # Download Miniconda (exact command requested)\n",
    "        __os.system('wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O /tmp/miniconda.sh')\n",
    "        # Run installer non-interactively\n",
    "        __sp.run(['bash', '/tmp/miniconda.sh', '-b', '-p', prefix], check=True)\n",
    "        conda_bin = str(__pl.Path(prefix) / 'bin' / 'conda')\n",
    "        if ACCEPT_CONDA_TOS and __os.path.exists(conda_bin):\n",
    "            __sp.run([conda_bin, 'tos', 'accept', '--override-channels', '--channel', 'https://repo.anaconda.com/pkgs/main'], check=True)\n",
    "            __sp.run([conda_bin, 'tos', 'accept', '--override-channels', '--channel', 'https://repo.anaconda.com/pkgs/r'], check=True)\n",
    "        print('‚úÖ Miniconda installed at', prefix)\n",
    "    else:\n",
    "        print('‚ö†Ô∏è Non-Linux platform detected; please use the appropriate Miniconda installer for your OS:')\n",
    "        print('   macOS (Intel): https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh')\n",
    "        print('   macOS (Apple Silicon): https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh')\n",
    "else:\n",
    "    print('‚ÑπÔ∏è Miniconda installation skipped (INSTALL_MINICONDA=False).')\n"
   ],
   "id": "cde1d690c336d2d"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeihW2hb4yNe",
    "outputId": "96f90dee-655d-4dfd-b50c-29b10ab83ac6"
   },
   "source": [
    "# Cell 2 - Hugging Face login (enter your token when prompted)\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "print('=' * 60)\n",
    "print('üîë Hugging Face Authentication Required')\n",
    "print('=' * 60)\n",
    "print('To use ESM3 model, you need a Hugging Face token.')\n",
    "print('1. Go to: https://huggingface.co/settings/tokens')\n",
    "print('2. Create a token with READ access')\n",
    "print('3. Grant access to: EvolutionaryScale/esm3-sm-open-v1')\n",
    "print('4. Paste the token below (or set HF_TOKEN env variable)')\n",
    "print('=' * 60)\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "try:\n",
    "    if HF_TOKEN:\n",
    "        print('Using token from HF_TOKEN environment variable...')\n",
    "        login(token=HF_TOKEN)\n",
    "        print('‚úÖ Logged in successfully!')\n",
    "    else:\n",
    "        login()  # interactive prompt on Colab / local\n",
    "        print('‚úÖ Logged in successfully!')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Login failed: {e}')\n",
    "    print('Please check your token and try again.')\n",
    "    raise\n"
   ],
   "id": "YeihW2hb4yNe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFdbI4cs4yNe",
    "outputId": "d9ba8aaf-05cc-48ad-c2a1-34c05435d3b3"
   },
   "source": [
    "# Cell 3 - Setup directories and imports\n",
    "from pathlib import Path\n",
    "import os, subprocess, shutil\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# Use a separate run directory to avoid clashing with the package name\n",
    "BASE = Path('/content/protflow_runs') if Path('/content').exists() else (Path.cwd() / 'runs')\n",
    "GBK_DIR = BASE / 'gbk_input'\n",
    "PDB_DIR = BASE / 'pdbs'\n",
    "\n",
    "for d in [BASE, GBK_DIR, PDB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Base dir setup at', BASE)\n"
   ],
   "id": "aFdbI4cs4yNe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 3b - Import modular helpers (new)\n",
    "# Ensure the repository root is at the front of sys.path so imports resolve to the package, not a shadowing data folder.\n",
    "from pathlib import Path as _Path  # local import to avoid ordering issues if user skips cells\n",
    "import sys as _sys, importlib as _importlib, os as _os\n",
    "\n",
    "_repo_candidates = [_Path.cwd(), _Path('/content/ProtFlow')]\n",
    "_repo_root = None\n",
    "for _cand in _repo_candidates:\n",
    "    if (_cand / 'esm3_pipeline' / '__init__.py').exists():\n",
    "        _repo_root = _cand\n",
    "        break\n",
    "\n",
    "if _repo_root is not None:\n",
    "    _repo_root_str = str(_repo_root)\n",
    "    # Ensure repo is first on sys.path\n",
    "    if _repo_root_str in _sys.path:\n",
    "        _sys.path.remove(_repo_root_str)\n",
    "    _sys.path.insert(0, _repo_root_str)\n",
    "    # Purge stale cached modules from previous failed imports\n",
    "    for _m in list(_sys.modules):\n",
    "        if _m == 'esm3_pipeline' or _m.startswith('esm3_pipeline.'):\n",
    "            _sys.modules.pop(_m, None)\n",
    "    _importlib.invalidate_caches()\n",
    "else:\n",
    "    print('‚ö†Ô∏è Could not find esm3_pipeline package; ensure the repo is cloned (e.g., /content/ProtFlow).')\n",
    "\n",
    "# Warn if a top-level shadowing folder exists on Colab\n",
    "_shadow = _Path('/content/esm3_pipeline')\n",
    "if _shadow.exists():\n",
    "    print('‚ÑπÔ∏è Note: /content/esm3_pipeline exists; using repo package from', _repo_root)\n",
    "\n",
    "from esm3_pipeline.seq_parser import extract_proteins_from_gbk, filter_and_select\n",
    "from esm3_pipeline.esm3_predict import load_esm3_small, predict_pdbs\n",
    "from esm3_pipeline.p2rank import ensure_p2rank, run_p2rank_on_pdbs\n",
    "from esm3_pipeline.ligand_prep import smiles_or_file_to_pdbqt\n",
    "from esm3_pipeline.vina_dock import run_vina\n",
    "from esm3_pipeline.reporting import build_report\n"
   ],
   "id": "41ddd3194f427d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 3c - Optional: Download sample GenBank file for testing\n",
    "print('=' * 60)\n",
    "print('üì• Sample Data (Optional)')\n",
    "print('=' * 60)\n",
    "print('Download a sample GenBank file for testing?')\n",
    "print('This will download a small bacterial genome for demonstration.')\n",
    "print()\n",
    "\n",
    "download_sample = input('Download sample data? (y/N): ').strip().lower() == 'y'\n",
    "\n",
    "if download_sample:\n",
    "    import urllib.request\n",
    "    sample_url = 'https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.gbff.gz'\n",
    "    sample_file = GBK_DIR / 'sample.gbff.gz'\n",
    "\n",
    "    try:\n",
    "        print('Downloading sample file...')\n",
    "        urllib.request.urlretrieve(sample_url, sample_file)\n",
    "\n",
    "        # Decompress\n",
    "        import gzip\n",
    "        with gzip.open(sample_file, 'rb') as f_in:\n",
    "            with open(sample_file.with_suffix(''), 'wb') as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "\n",
    "        sample_file.unlink()  # Remove .gz\n",
    "        print(f'‚úÖ Sample data downloaded to: {GBK_DIR}')\n",
    "        print('Note: This is a full genome - Cell 5 will help you select a subset.')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Download failed: {e}')\n",
    "        print('You can manually upload .gbk files to:', GBK_DIR)\n",
    "else:\n",
    "    print('Skipped. You can upload your own .gbk/.gbff files to:', GBK_DIR)\n",
    "\n",
    "print()\n"
   ],
   "id": "ddeea2806c95da01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 4 - Parse GenBank files and extract protein translations (modular)\n",
    "print('=' * 60)\n",
    "print('üìÑ Step 1: Extract Protein Sequences from GenBank Files')\n",
    "print('=' * 60)\n",
    "print(f'Looking for .gbk/.gbff files in: {GBK_DIR}')\n",
    "print()\n",
    "\n",
    "fasta_all = BASE / 'all_proteins.faa'\n",
    "try:\n",
    "    count = extract_proteins_from_gbk(GBK_DIR, fasta_all)\n",
    "    print(f'‚úÖ Wrote {count} protein sequences to {fasta_all}')\n",
    "except Exception as e:\n",
    "    print(f'‚ö†Ô∏è Error extracting proteins: {e}')\n",
    "    count = 0\n",
    "\n",
    "if count == 0:\n",
    "    print()\n",
    "    print('‚ö†Ô∏è No sequences found in GenBank files.')\n",
    "    print('You can:')\n",
    "    print('  1. Upload .gbk or .gbff files to:', GBK_DIR)\n",
    "    print('  2. Paste a single amino acid sequence below')\n",
    "    print()\n",
    "    seq = input('Paste amino acid sequence (or press Enter to skip): ').strip()\n",
    "    if seq:\n",
    "        with open(fasta_all, 'w') as f:\n",
    "            f.write('>user_sequence\\n' + seq + '\\n')\n",
    "        print(f'‚úÖ Saved single sequence to {fasta_all}')\n",
    "        count = 1\n",
    "    else:\n",
    "        print('‚ö†Ô∏è No sequences provided. Please add GenBank files and re-run.')\n",
    "else:\n",
    "    print()\n",
    "    print('Next: Run Cell 5 to select candidates for structure prediction.')\n"
   ],
   "id": "64017e3aa2062735"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DCYk03aO4yNf"
   },
   "source": [
    "# Cell 5 - Quick filter and selection of candidates (modular)\n",
    "print('=' * 60)\n",
    "print('üîç Step 2: Filter and Select Candidates')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    records = list(SeqIO.parse(str(fasta_all), 'fasta'))\n",
    "    print(f'Total sequences loaded: {len(records)}')\n",
    "\n",
    "    if len(records) == 0:\n",
    "        print('‚ùå No sequences found. Please run Cell 4 first.')\n",
    "        raise ValueError(\"No sequences to process\")\n",
    "\n",
    "    # Show length distribution\n",
    "    lengths = [len(r.seq) for r in records]\n",
    "    print(f'Sequence length range: {min(lengths)} - {max(lengths)} aa')\n",
    "    print()\n",
    "\n",
    "    # Get filter parameters with defaults\n",
    "    print('Filter parameters (press Enter to use defaults):')\n",
    "    min_len = input('  Min length (aa) [default 50]: ').strip()\n",
    "    min_len = int(min_len) if min_len else 50\n",
    "\n",
    "    max_len = input('  Max length (aa) [default 1200]: ').strip()\n",
    "    max_len = int(max_len) if max_len else 1200\n",
    "\n",
    "    num = input('  Number of candidates to predict [default 10]: ').strip()\n",
    "    num = int(num) if num else 10\n",
    "\n",
    "    print()\n",
    "    print(f'Filtering: length {min_len}-{max_len} aa, selecting up to {num} sequences...')\n",
    "\n",
    "    selected_fasta = BASE / 'selected.faa'\n",
    "    selected = filter_and_select(fasta_all, min_len, max_len, num, selected_fasta)\n",
    "\n",
    "    print(f'‚úÖ Selected {len(selected)} candidates saved to {selected_fasta}')\n",
    "\n",
    "    if len(selected) == 0:\n",
    "        print('‚ö†Ô∏è No sequences match the filter criteria. Try adjusting the length range.')\n",
    "    else:\n",
    "        print()\n",
    "        print('Next: Run Cell 6 to load the ESM3 model.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Error during selection: {e}')\n",
    "    raise\n"
   ],
   "id": "DCYk03aO4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P73MwiTX4yNf"
   },
   "source": [
    "# Cell 6 - Load ESM3-sm model (modular)\n",
    "print('=' * 60)\n",
    "print('üß¨ Step 3: Load ESM3 Structure Prediction Model')\n",
    "print('=' * 60)\n",
    "\n",
    "# Check GPU availability\n",
    "import torch as _torch\n",
    "if _torch.cuda.is_available():\n",
    "    print(f'‚úÖ GPU detected: {_torch.cuda.get_device_name(0)}')\n",
    "    print(f'   Memory: {_torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')\n",
    "else:\n",
    "    print('‚ö†Ô∏è No GPU detected. Model will run on CPU (slower).')\n",
    "    print('   Tip: In Colab, enable GPU via Runtime ‚Üí Change runtime type ‚Üí GPU')\n",
    "\n",
    "print()\n",
    "print('Loading ESM3-sm model (this may take a few minutes)...')\n",
    "\n",
    "try:\n",
    "    model, device = load_esm3_small()\n",
    "    print(f'‚úÖ Model loaded successfully on {device}')\n",
    "    print()\n",
    "    print('Next: Run Cell 7 to predict protein structures.')\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Failed to load model: {e}')\n",
    "    print('Common issues:')\n",
    "    print('  - Insufficient GPU memory (try restarting runtime)')\n",
    "    print('  - Network timeout (try running the cell again)')\n",
    "    print('  - Missing HuggingFace token (re-run Cell 2)')\n",
    "    raise\n"
   ],
   "id": "P73MwiTX4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1RZSRJHa4yNf"
   },
   "source": [
    "# Cell 7 - Predict structures with ESM3-sm (modular)\n",
    "print('=' * 60)\n",
    "print('üîÆ Step 4: Predict Protein Structures')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    selected_records = list(SeqIO.parse(str(selected_fasta), 'fasta'))\n",
    "    print(f'Predicting structures for {len(selected_records)} proteins...')\n",
    "    print('‚è≥ This may take several minutes depending on sequence length and GPU.')\n",
    "    print()\n",
    "\n",
    "    for i, rec in enumerate(selected_records, 1):\n",
    "        print(f'  [{i}/{len(selected_records)}] {rec.id} ({len(rec.seq)} aa)')\n",
    "\n",
    "    print()\n",
    "    predict_pdbs(model, selected_records, PDB_DIR)\n",
    "\n",
    "    # Count successful predictions\n",
    "    pdb_files = list(PDB_DIR.glob('*.pdb'))\n",
    "    print()\n",
    "    print(f'‚úÖ Generated {len(pdb_files)} PDB files in {PDB_DIR}')\n",
    "    print()\n",
    "    print('Next: Run Cell 8 to download and setup P2Rank for pocket detection.')\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('‚ùå Selected sequences file not found. Please run Cell 5 first.')\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Structure prediction failed: {e}')\n",
    "    print('Tip: If you see CUDA out of memory, try:')\n",
    "    print('  - Reducing the number of sequences in Cell 5')\n",
    "    print('  - Restarting the runtime to free GPU memory')\n",
    "    raise\n"
   ],
   "id": "1RZSRJHa4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 8 - Download and setup P2Rank 2.5.x (modular)\n",
    "print('=' * 60)\n",
    "print('üéØ Step 5: Setup P2Rank for Pocket Detection')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    # Check Java first\n",
    "    print('Checking Java installation...')\n",
    "    !java -version\n",
    "    print()\n",
    "\n",
    "    print('Downloading P2Rank (this may take a moment)...')\n",
    "    P2_JAR = ensure_p2rank(BASE)\n",
    "\n",
    "    if P2_JAR is None:\n",
    "        print('‚ùå Failed to locate p2rank.jar under', BASE / 'p2rank')\n",
    "        print('Please check your internet connection and try again.')\n",
    "    else:\n",
    "        print(f'‚úÖ P2Rank ready at: {P2_JAR}')\n",
    "        print()\n",
    "        print('Next: Run Cell 9 to detect binding pockets.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'‚ùå P2Rank setup failed: {e}')\n",
    "    print('Common issues:')\n",
    "    print('  - Java not installed (should be installed in Cell 1 on Colab)')\n",
    "    print('  - Network timeout during download')\n",
    "    print('  - Insufficient disk space')\n",
    "    raise\n",
    "\n"
   ],
   "id": "f16baadbc1e0ee78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 9 - Run P2Rank on predicted PDBs and extract top pocket centers (modular)\n",
    "print('=' * 60)\n",
    "print('üéØ Step 6: Detect Binding Pockets')\n",
    "print('=' * 60)\n",
    "\n",
    "POCKET_RESULTS = []\n",
    "if P2_JAR is not None:\n",
    "    try:\n",
    "        print(f'Running P2Rank on PDB files in {PDB_DIR}...')\n",
    "        print('‚è≥ This may take a few minutes...')\n",
    "        print()\n",
    "\n",
    "        results = run_p2rank_on_pdbs(P2_JAR, PDB_DIR)\n",
    "        import pandas as _pd\n",
    "        pockets_df = _pd.DataFrame(results)\n",
    "\n",
    "        if not pockets_df.empty:\n",
    "            pockets_df.to_csv(BASE / 'pockets_summary.csv', index=False)\n",
    "            print(f'‚úÖ Found {len(pockets_df)} pockets across {pockets_df[\"pdb\"].nunique()} structures')\n",
    "            print(f'   Results saved to: {BASE / \"pockets_summary.csv\"}')\n",
    "            print()\n",
    "            print('Next: Run Cell 10 to prepare a ligand for docking.')\n",
    "        else:\n",
    "            print('‚ö†Ô∏è No pockets detected. Check PDB files and P2Rank output.')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Pocket detection failed: {e}')\n",
    "        pockets_df = pd.DataFrame()\n",
    "        raise\n",
    "else:\n",
    "    pockets_df = pd.DataFrame()\n",
    "    print('‚ö†Ô∏è Skipping P2Rank: p2rank.jar not found (run Cell 8 first)')\n"
   ],
   "id": "8c2a90a5388d4a76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 10 - Prepare ligand: SMILES or uploaded file (modular)\n",
    "print('=' * 60)\n",
    "print('üíä Step 7: Prepare Ligand for Docking')\n",
    "print('=' * 60)\n",
    "print('You can provide either:')\n",
    "print('  - A SMILES string (e.g., \"CCO\" for ethanol)')\n",
    "print('  - A path to a ligand file (SDF, MOL, PDB)')\n",
    "print('  - Leave blank to skip docking')\n",
    "print()\n",
    "\n",
    "lig_in = input('Enter ligand SMILES or file path (or press Enter to skip): ').strip()\n",
    "\n",
    "if lig_in:\n",
    "    try:\n",
    "        lig_pdbqt = smiles_or_file_to_pdbqt(lig_in, BASE)\n",
    "        if lig_pdbqt:\n",
    "            print(f'‚úÖ Ligand prepared successfully: {lig_pdbqt}')\n",
    "            print()\n",
    "            print('Next: Run Cell 11 to perform docking.')\n",
    "        else:\n",
    "            print('‚ùå Failed to prepare ligand. Check input and try again.')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Ligand preparation failed: {e}')\n",
    "        print('Tips:')\n",
    "        print('  - Ensure SMILES is valid')\n",
    "        print('  - Ensure file exists and is in a supported format')\n",
    "        print('  - OpenBabel must be installed (should be in Cell 1)')\n",
    "        lig_pdbqt = None\n",
    "        raise\n",
    "else:\n",
    "    lig_pdbqt = None\n",
    "    print('‚ÑπÔ∏è No ligand provided; docking will be skipped.')\n"
   ],
   "id": "79b49a7c7e4cae97"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lc13Wsx84yNg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "578a84df-7b20-49b7-c377-d2dfd07cba1b"
   },
   "source": [
    "# Cell 11 - Vina docking into top pocket centers (modular)\n",
    "print('=' * 60)\n",
    "print('üî¨ Step 8: Molecular Docking with AutoDock Vina')\n",
    "print('=' * 60)\n",
    "\n",
    "if lig_pdbqt is not None and not pockets_df.empty:\n",
    "    try:\n",
    "        print(f'Running docking into {len(pockets_df)} pockets...')\n",
    "        print('‚è≥ This may take several minutes...')\n",
    "        print()\n",
    "\n",
    "        dfg = run_vina(lig_pdbqt, pockets_df, BASE)\n",
    "        dfg.to_csv(BASE / 'vina_results.csv', index=False)\n",
    "\n",
    "        # Show results summary\n",
    "        successful = dfg['affinity'].notna().sum()\n",
    "        print(f'‚úÖ Docking completed: {successful}/{len(dfg)} successful')\n",
    "\n",
    "        if successful > 0:\n",
    "            best_idx = dfg['affinity'].idxmin()\n",
    "            best_row = dfg.loc[best_idx]\n",
    "            print(f'   Best affinity: {best_row[\"affinity\"]:.2f} kcal/mol')\n",
    "            print(f'   PDB: {Path(best_row[\"pdb\"]).name}')\n",
    "            print(f'   Pocket: {best_row[\"pocket_rank\"]}')\n",
    "\n",
    "        print(f'   Results saved to: {BASE / \"vina_results.csv\"}')\n",
    "        print()\n",
    "        print('Next: Run Cell 12 to generate the final report.')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Docking failed: {e}')\n",
    "        print('Tips:')\n",
    "        print('  - Ensure AutoDock Vina is installed (should be in Cell 1)')\n",
    "        print('  - Check that pockets were detected successfully')\n",
    "        raise\n",
    "else:\n",
    "    if lig_pdbqt is None:\n",
    "        print('‚ÑπÔ∏è Skipping docking: no ligand provided')\n",
    "    elif pockets_df.empty:\n",
    "        print('‚ö†Ô∏è Skipping docking: no pockets detected')\n",
    "    else:\n",
    "        print('‚ÑπÔ∏è Skipping docking: missing requirements')\n"
   ],
   "id": "Lc13Wsx84yNg",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kPGOlRuy4yNg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "7cdacf3b-49c9-4521-beaf-f3d1e73832a2"
   },
   "source": [
    "# Cell 12 - Generate PDF report (modular)\n",
    "print('=' * 60)\n",
    "print('üìä Step 9: Generate Summary Report')\n",
    "print('=' * 60)\n",
    "\n",
    "try:\n",
    "    from pathlib import Path as _Path\n",
    "    report_path = BASE / 'esm3_results_report.pdf'\n",
    "\n",
    "    print('Building PDF report...')\n",
    "    build_report(BASE, PDB_DIR, report_path)\n",
    "\n",
    "    print(f'‚úÖ Report generated successfully: {report_path}')\n",
    "    print()\n",
    "    print('=' * 60)\n",
    "    print('üéâ Pipeline Complete!')\n",
    "    print('=' * 60)\n",
    "    print('Generated files:')\n",
    "    print(f'  - Report: {report_path}')\n",
    "    print(f'  - PDB structures: {PDB_DIR}')\n",
    "    print(f'  - Pockets: {BASE / \"pockets_summary.csv\"}')\n",
    "    if lig_pdbqt is not None:\n",
    "        print(f'  - Docking results: {BASE / \"vina_results.csv\"}')\n",
    "    print()\n",
    "    print('On Colab: Use the file browser (left panel) to download files.')\n",
    "    print('Locally: Check the output directory:', BASE)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'‚ùå Report generation failed: {e}')\n",
    "    print('Note: Some output files may still be available in:', BASE)\n",
    "    raise\n"
   ],
   "id": "kPGOlRuy4yNg",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 13 - Optional: Visualize structures (interactive)\n",
    "print('=' * 60)\n",
    "print('üëÅÔ∏è 3D Structure Visualization (Optional)')\n",
    "print('=' * 60)\n",
    "\n",
    "visualize = input('Visualize a structure in 3D? (y/N): ').strip().lower() == 'y'\n",
    "\n",
    "if visualize:\n",
    "    try:\n",
    "        import py3Dmol\n",
    "\n",
    "        # List available PDB files\n",
    "        pdb_files = sorted(PDB_DIR.glob('*.pdb'))\n",
    "        if not pdb_files:\n",
    "            print('‚ùå No PDB files found to visualize.')\n",
    "        else:\n",
    "            print(f'Available PDB files ({len(pdb_files)}):')\n",
    "            for i, p in enumerate(pdb_files[:10], 1):\n",
    "                print(f'  {i}. {p.name}')\n",
    "\n",
    "            if len(pdb_files) > 10:\n",
    "                print(f'  ... and {len(pdb_files) - 10} more')\n",
    "\n",
    "            print()\n",
    "            idx = input(f'Select file number (1-{min(10, len(pdb_files))}) or press Enter for first: ').strip()\n",
    "\n",
    "            if idx:\n",
    "                try:\n",
    "                    selected_pdb = pdb_files[int(idx) - 1]\n",
    "                except (ValueError, IndexError):\n",
    "                    print('Invalid selection, using first file')\n",
    "                    selected_pdb = pdb_files[0]\n",
    "            else:\n",
    "                selected_pdb = pdb_files[0]\n",
    "\n",
    "            print(f'Visualizing: {selected_pdb.name}')\n",
    "\n",
    "            # Create viewer\n",
    "            view = py3Dmol.view(width=800, height=600)\n",
    "\n",
    "            # Load structure\n",
    "            with open(selected_pdb) as f:\n",
    "                pdb_data = f.read()\n",
    "\n",
    "            view.addModel(pdb_data, 'pdb')\n",
    "            view.setStyle({'cartoon': {'color': 'spectrum'}})\n",
    "\n",
    "            # Add surface if pockets exist\n",
    "            pock_csv = BASE / 'pockets_summary.csv'\n",
    "            if pock_csv.exists():\n",
    "                import pandas as pd\n",
    "                import ast\n",
    "                dfp = pd.read_csv(pock_csv)\n",
    "                # Filter for this PDB\n",
    "                pdb_pockets = dfp[dfp['pdb'].str.contains(selected_pdb.stem)]\n",
    "\n",
    "                if not pdb_pockets.empty:\n",
    "                    # Show pocket centers as spheres\n",
    "                    for _, row in pdb_pockets.head(3).iterrows():\n",
    "                        try:\n",
    "                            center = ast.literal_eval(row['center']) if isinstance(row['center'], str) else row['center']\n",
    "                            cx, cy, cz = center\n",
    "                            view.addSphere({\n",
    "                                'center': {'x': cx, 'y': cy, 'z': cz},\n",
    "                                'radius': 5.0,\n",
    "                                'color': 'red',\n",
    "                                'alpha': 0.5\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            view.zoomTo()\n",
    "            view.show()\n",
    "\n",
    "            print('‚úÖ Structure loaded. Red spheres indicate predicted binding pockets.')\n",
    "\n",
    "    except ImportError:\n",
    "        print('‚ùå py3Dmol not installed. Install with: pip install py3Dmol')\n",
    "    except Exception as e:\n",
    "        print(f'‚ùå Visualization failed: {e}')\n",
    "else:\n",
    "    print('Skipped visualization.')\n",
    "\n"
   ],
   "id": "60bdbfe1caae54d1"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVLM2dt54yNg"
   },
   "source": [
    "### Final: Download files\n",
    "Use the left file browser in Colab to download `esm3_results_report.pdf`, the PDBs in `/content/protflow_runs/pdbs`, and docking outputs in `/content/protflow_runs`.\n"
   ],
   "id": "hVLM2dt54yNg"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
