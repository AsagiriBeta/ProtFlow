{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwJG790p4yNU"
   },
   "source": [
    "# Modular pipeline for protein structure prediction, pocket detection, ligand docking, and BGC annotation\n",
    "\n",
    "**Purpose:**\n",
    "- Parse `.gbk` files to extract protein CDS sequences\n",
    "- Use `esm3-sm-open-v1` (ESM3 small) to predict protein structure (PDB)\n",
    "- Run **P2Rank** for pocket detection\n",
    "- Prepare ligand (SMILES or upload) and run **AutoDock Vina** docking\n",
    "- Generate a simple PDF summary report and provide downloadable PDB/PDBQT files\n",
    "- Optional: Run antiSMASH on GBK/GBFF (if available)\n",
    "\n",
    "**Notes before running:**\n",
    "1. This notebook is designed for Google Colab with GPU enabled. Go to `Runtime → Change runtime type → GPU`.\n",
    "2. You must have a Hugging Face token with access to `esm3-sm-open-v1`. Create one at https://huggingface.co/settings/tokens and grant access to the gated repo if needed.\n",
    "3. The notebook installs some system packages (OpenBabel, Vina, Java). It may take several minutes.\n",
    "4. This pipeline uses ESM3-sm (small) to avoid excessive memory requirements on Colab.\n",
    "5. Optional antiSMASH: not required for the main pipeline. If you want to run antiSMASH (Cell 8a), install it first on your local machine or a conda env:\n",
    "   - Bioconda (recommended):\n",
    "     ```zsh\n",
    "     conda config --add channels conda-forge\n",
    "     conda config --add channels bioconda\n",
    "     conda create -y -n antismash antismash\n",
    "     conda activate antismash\n",
    "     download-antismash-databases\n",
    "     # optional warm-up caches\n",
    "     antismash --prepare-data\n",
    "     ```\n",
    "   - Docker (standalone full image; large download):\n",
    "     ```zsh\n",
    "     mkdir -p ~/bin\n",
    "     curl -q https://dl.secondarymetabolites.org/releases/latest/docker-run_antismash-full > ~/bin/run_antismash\n",
    "     chmod a+x ~/bin/run_antismash\n",
    "     # Use absolute paths; args order: input first, then output dir\n",
    "     run_antismash /abs/path/input.gbk /abs/path/out\n",
    "     ```\n",
    "   The notebook will automatically skip the antiSMASH step if it is not installed/available.\n",
    "\n",
    "> Colab note: we do not use `requirements.txt` here to avoid potential RDKit/NumPy resolver conflicts on Colab. We install the minimal Python packages directly below.\n"
   ],
   "id": "NwJG790p4yNU"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 0 - Get code (Colab)\n",
    "# If running on Colab (/content exists), clone the repo into /content/ProtFlow if not present,\n",
    "# change directory, and remove any shadowing data folder.\n",
    "from pathlib import Path as __Path\n",
    "if __Path('/content').exists():\n",
    "    # shell and magic are available in IPython/Colab\n",
    "    !test -d /content/ProtFlow || git clone https://github.com/AsagiriBeta/ProtFlow.git /content/ProtFlow\n",
    "    %cd /content/ProtFlow\n",
    "    !rm -rf /content/esm3_pipeline || true\n",
    "    print('Repo ready at /content/ProtFlow')\n",
    "else:\n",
    "    print('Not running on Colab; skipping clone step.')\n"
   ],
   "id": "6aae8034c8e014b5"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RBLW4IYA4yNd"
   },
   "source": [
    "# Cell 1 - Install dependencies (run once)\n",
    "!pip install -q esm rdkit biopython py3Dmol tqdm requests reportlab pandas matplotlib huggingface_hub\n",
    "!apt-get -qq update\n",
    "!apt-get -qq install -y default-jre openbabel unzip wget python3-tk\n",
    "!apt-get -qq install -y autodock-vina fpocket || true\n",
    "\n",
    "print('✅ Install finished. Restart the runtime if prompted.')\n"
   ],
   "id": "RBLW4IYA4yNd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeihW2hb4yNe",
    "outputId": "96f90dee-655d-4dfd-b50c-29b10ab83ac6"
   },
   "source": [
    "# Cell 2 - Hugging Face login (enter your token when prompted)\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "print('Paste your Hugging Face token (it will not be stored here).')\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "if HF_TOKEN:\n",
    "    login(token=HF_TOKEN)\n",
    "else:\n",
    "    login()  # interactive prompt on Colab / local\n"
   ],
   "id": "YeihW2hb4yNe",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFdbI4cs4yNe",
    "outputId": "d9ba8aaf-05cc-48ad-c2a1-34c05435d3b3"
   },
   "source": [
    "# Cell 3 - Setup directories and imports\n",
    "from pathlib import Path\n",
    "import os, subprocess, shutil\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "# Use a separate run directory to avoid clashing with the package name\n",
    "BASE = Path('/content/protflow_runs') if Path('/content').exists() else (Path.cwd() / 'runs')\n",
    "GBK_DIR = BASE / 'gbk_input'\n",
    "PDB_DIR = BASE / 'pdbs'\n",
    "\n",
    "for d in [BASE, GBK_DIR, PDB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Base dir setup at', BASE)\n"
   ],
   "id": "aFdbI4cs4yNe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 3b - Import modular helpers (new)\n",
    "# Ensure the repository root is at the front of sys.path so imports resolve to the package, not a shadowing data folder.\n",
    "from pathlib import Path as _Path  # local import to avoid ordering issues if user skips cells\n",
    "import sys as _sys, importlib as _importlib, os as _os\n",
    "\n",
    "_repo_candidates = [_Path.cwd(), _Path('/content/ProtFlow')]\n",
    "_repo_root = None\n",
    "for _cand in _repo_candidates:\n",
    "    if (_cand / 'esm3_pipeline' / '__init__.py').exists():\n",
    "        _repo_root = _cand\n",
    "        break\n",
    "\n",
    "if _repo_root is not None:\n",
    "    _repo_root_str = str(_repo_root)\n",
    "    # Ensure repo is first on sys.path\n",
    "    if _repo_root_str in _sys.path:\n",
    "        _sys.path.remove(_repo_root_str)\n",
    "    _sys.path.insert(0, _repo_root_str)\n",
    "    # Purge stale cached modules from previous failed imports\n",
    "    for _m in list(_sys.modules):\n",
    "        if _m == 'esm3_pipeline' or _m.startswith('esm3_pipeline.'):\n",
    "            _sys.modules.pop(_m, None)\n",
    "    _importlib.invalidate_caches()\n",
    "else:\n",
    "    print('⚠️ Could not find esm3_pipeline package; ensure the repo is cloned (e.g., /content/ProtFlow).')\n",
    "\n",
    "# Warn if a top-level shadowing folder exists on Colab\n",
    "_shadow = _Path('/content/esm3_pipeline')\n",
    "if _shadow.exists():\n",
    "    print('ℹ️ Note: /content/esm3_pipeline exists; using repo package from', _repo_root)\n",
    "\n",
    "from esm3_pipeline.seq_parser import extract_proteins_from_gbk, filter_and_select\n",
    "from esm3_pipeline.esm3_predict import load_esm3_small, predict_pdbs\n",
    "from esm3_pipeline.p2rank import ensure_p2rank, run_p2rank_on_pdbs\n",
    "from esm3_pipeline.ligand_prep import smiles_or_file_to_pdbqt\n",
    "from esm3_pipeline.vina_dock import run_vina\n",
    "from esm3_pipeline.reporting import build_report\n",
    "from esm3_pipeline.antismash import is_antismash_available, run_antismash, get_runner\n"
   ],
   "id": "41ddd3194f427d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 4 - Parse GenBank files and extract protein translations (modular)\n",
    "fasta_all = BASE / 'all_proteins.faa'\n",
    "count = extract_proteins_from_gbk(GBK_DIR, fasta_all)\n",
    "print('Wrote', count, 'protein sequences to', fasta_all)\n",
    "\n",
    "if count == 0:\n",
    "    seq = input('No sequences found. Paste a single amino acid sequence (or press Enter to skip): ').strip()\n",
    "    if seq:\n",
    "        with open(fasta_all, 'w') as f:\n",
    "            f.write('>user_sequence\\n' + seq + '\\n')\n",
    "        print('Saved single sequence to', fasta_all)\n"
   ],
   "id": "64017e3aa2062735"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DCYk03aO4yNf"
   },
   "source": [
    "# Cell 5 - Quick filter and selection of candidates (modular)\n",
    "records = list(SeqIO.parse(str(fasta_all), 'fasta'))\n",
    "print('Total sequences loaded:', len(records))\n",
    "\n",
    "min_len = int(input('Min length (aa) [default 50]: ') or 50)\n",
    "max_len = int(input('Max length (aa) [default 1200]: ') or 1200)\n",
    "num = int(input('How many candidates to predict (default 10): ') or 10)\n",
    "selected_fasta = BASE / 'selected.faa'\n",
    "selected = filter_and_select(fasta_all, min_len, max_len, num, selected_fasta)\n",
    "print('Selected', len(selected), 'candidates saved to', selected_fasta)\n"
   ],
   "id": "DCYk03aO4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P73MwiTX4yNf"
   },
   "source": [
    "# Cell 6 - Load ESM3-sm model (modular)\n",
    "model, device = load_esm3_small()\n",
    "print('Model loaded to', device)\n"
   ],
   "id": "P73MwiTX4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1RZSRJHa4yNf"
   },
   "source": [
    "# Cell 7 - Predict structures with ESM3-sm (modular)\n",
    "selected_records = list(SeqIO.parse(str(selected_fasta), 'fasta'))\n",
    "for rec in selected_records:\n",
    "    print('Predicting', rec.id, 'len', len(rec.seq))\n",
    "predict_pdbs(model, selected_records, PDB_DIR)\n",
    "print('Saved PDB files to', PDB_DIR)\n"
   ],
   "id": "1RZSRJHa4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3xEXrNGC4yNf"
   },
   "source": [
    "# Cell 8 - Download and setup P2Rank 2.5.x (modular)\n",
    "P2_JAR = ensure_p2rank(BASE)\n",
    "if P2_JAR is None:\n",
    "    print('❌ Failed to locate p2rank.jar under', BASE / 'p2rank')\n",
    "else:\n",
    "    print('P2Rank jar at', P2_JAR)\n",
    "    !java -version\n"
   ],
   "id": "3xEXrNGC4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 8a0 - Optional: Install antiSMASH via micromamba (Colab)\n",
    "from pathlib import Path as __P\n",
    "import os as __os, shutil as __shutil\n",
    "if __P('/content').exists():\n",
    "    do_install = input('Install antiSMASH env via micromamba now? (y/N): ').strip().lower() == 'y'\n",
    "    if do_install:\n",
    "        # Install micromamba into /content/bin if missing\n",
    "        if not __shutil.which('micromamba'):\n",
    "            !mkdir -p /content/bin\n",
    "            !curl -Ls \"https://micro.mamba.pm/api/micromamba/linux-64/latest\" -o /content/micromamba.tar.bz2\n",
    "            !tar -xjf /content/micromamba.tar.bz2 -C /content bin/micromamba\n",
    "            !mv /content/bin/micromamba /content/bin/micromamba\n",
    "            __os.environ['PATH'] = '/content/bin:' + __os.environ.get('PATH','')\n",
    "        # Create env and install antiSMASH\n",
    "        !micromamba create -y -n antismash -c conda-forge -c bioconda antismash\n",
    "        # Download databases\n",
    "        !micromamba run -n antismash download-antismash-databases\n",
    "        print('antiSMASH env ready. Proceed to Cell 8a to run it.')\n",
    "else:\n",
    "    print('Skipping micromamba setup (not Colab).')\n"
   ],
   "id": "56929fd337215e4e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9okZIO4O4yNf",
    "outputId": "acd4dc2e-662a-49b4-b53c-9891b5bd18d0"
   },
   "source": [
    "# Cell 8a - Optional: antiSMASH analysis (if available)\n",
    "# You can specify a conda env name via ANTISMASH_ENV (default 'antismash').\n",
    "import os as __os\n",
    "__os.environ.setdefault('ANTISMASH_ENV', 'antismash')\n",
    "run_as = input('Run antiSMASH on a GBK/GBFF? (y/N): ').strip().lower() == 'y'\n",
    "if run_as:\n",
    "    runner = get_runner()\n",
    "    if not is_antismash_available():\n",
    "        print('⚠️ antiSMASH is not available in this environment; skipping')\n",
    "        if runner is None:\n",
    "            print('   Tips:')\n",
    "            print('     - Use Bioconda to create an env: conda create -n antismash antismash && download-antismash-databases')\n",
    "            print('     - Then set ANTISMASH_ENV=antismash and ensure conda/mamba is on PATH')\n",
    "            print('     - Or install the Docker wrapper: run_antismash (full image)')\n",
    "        else:\n",
    "            print('   Detected runner but failed to probe with --help:', ' '.join(runner))\n",
    "    else:\n",
    "        print('antiSMASH runner:', ' '.join(runner))\n",
    "        # Choose first GBK/GBFF by default\n",
    "        gbk_files = sorted(GBK_DIR.glob('*.gbk')) + sorted(GBK_DIR.glob('*.gbff'))\n",
    "        default_inp = str(gbk_files[0]) if gbk_files else ''\n",
    "        as_inp = input(f'Path to GBK/GBFF [default {default_inp}]: ').strip() or default_inp\n",
    "        if as_inp and Path(as_inp).exists():\n",
    "            out_as = BASE / 'antismash_out'\n",
    "            res = run_antismash(Path(as_inp), out_as)\n",
    "            print('antiSMASH results at', res)\n",
    "        else:\n",
    "            print('No valid input file; skipped antiSMASH')\n",
    "else:\n",
    "    print('antiSMASH step skipped')\n"
   ],
   "id": "9okZIO4O4yNf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 9 - Run P2Rank on predicted PDBs and extract top pocket centers (modular)\n",
    "POCKET_RESULTS = []\n",
    "if P2_JAR is not None:\n",
    "    results = run_p2rank_on_pdbs(P2_JAR, PDB_DIR)\n",
    "    import pandas as _pd\n",
    "    pockets_df = _pd.DataFrame(results)\n",
    "    if not pockets_df.empty:\n",
    "        pockets_df.to_csv(BASE / 'pockets_summary.csv', index=False)\n",
    "    print('✅ Saved pockets summary to', BASE / 'pockets_summary.csv')\n",
    "else:\n",
    "    pockets_df = pd.DataFrame()\n",
    "    print('⚠️ Skipping P2Rank: p2rank.jar not found')\n"
   ],
   "id": "8c2a90a5388d4a76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Cell 10 - Prepare ligand: SMILES or uploaded file (modular)\n",
    "lig_in = input('Enter ligand SMILES or local path to ligand file (SDF/MOL/PDB). Leave blank to skip docking: ').strip()\n",
    "lig_pdbqt = smiles_or_file_to_pdbqt(lig_in, BASE) if lig_in else None\n",
    "if lig_pdbqt:\n",
    "    print('Ligand prepared at', lig_pdbqt)\n",
    "else:\n",
    "    print('No ligand provided; skipping docking')\n"
   ],
   "id": "79b49a7c7e4cae97"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Lc13Wsx84yNg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "578a84df-7b20-49b7-c377-d2dfd07cba1b"
   },
   "source": [
    "# Cell 11 - Vina docking into top pocket centers (modular)\n",
    "if lig_pdbqt is not None and not pockets_df.empty:\n",
    "    dfg = run_vina(lig_pdbqt, pockets_df, BASE)\n",
    "    dfg.to_csv(BASE / 'vina_results.csv', index=False)\n",
    "    print('✅ Vina docking completed; results at', BASE / 'vina_results.csv')\n",
    "else:\n",
    "    print('Skipping docking: ligand or pockets missing')\n"
   ],
   "id": "Lc13Wsx84yNg",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kPGOlRuy4yNg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "7cdacf3b-49c9-4521-beaf-f3d1e73832a2"
   },
   "source": [
    "# Cell 12 - Generate PDF report (modular)\n",
    "from pathlib import Path as _Path\n",
    "report_path = BASE / 'esm3_results_report.pdf'\n",
    "build_report(BASE, PDB_DIR, report_path)\n",
    "print('✅ Report built at', report_path)\n"
   ],
   "id": "kPGOlRuy4yNg",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVLM2dt54yNg"
   },
   "source": [
    "### Final: Download files\n",
    "Use the left file browser in Colab to download `esm3_results_report.pdf`, the PDBs in `/content/protflow_runs/pdbs`, and docking outputs in `/content/protflow_runs`.\n"
   ],
   "id": "hVLM2dt54yNg"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
